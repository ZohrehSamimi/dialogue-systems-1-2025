import * as SDK from "microsoft-cognitiveservices-speech-sdk";
import { AudioConfig } from "microsoft-cognitiveservices-speech-sdk";
export interface SpeechSynthesisEventProps {
    boundaryType: string;
    name: string;
    elapsedTime: number;
    duration: number;
    animation: any;
}
export interface SpeechRecognitionResultListItem {
    confidence: number;
    transcript: string;
}
export interface SpeechRecognitionResultList extends Array<SpeechRecognitionResultListItem> {
    isFinal?: boolean;
}
interface Credentials {
    region?: string;
    subscriptionKey?: string;
    authorizationToken?: string;
    customVoiceHostname?: string;
    speechRecognitionHostname?: string;
    speechSynthesisHostname?: string;
}
interface PonyfillOptions {
    credentials: Credentials;
    looseEvents?: boolean;
    audioContext?: AudioContext;
    ponyfill?: {
        AudioContext?: AudioContext;
    };
    speechSynthesisDeploymentId?: string;
}
export interface PatchOptions extends PonyfillOptions {
    fetchCredentials?: Function;
    audioConfig?: AudioConfig;
    enableTelemetry?: boolean;
    referenceGrammars?: any;
    speechRecognitionEndpointId?: string;
    textNormalization?: string;
    [key: string]: any;
}
export class SpeechGrammarList {
    _phrases: Array<string>;
    addFromString(): void;
    get phrases(): Array<string>;
    set phrases(value: Array<string> | string);
}
interface VoiceProps {
    gender: string;
    lang: string;
    voiceURI: string;
}
declare class {
    _default: boolean;
    _gender: string;
    _lang: string;
    _localService: boolean;
    _name: string;
    _voiceURI: string;
    constructor({ gender, lang, voiceURI }: VoiceProps);
    get default(): boolean;
    get gender(): string;
    get lang(): string;
    get localService(): boolean;
    get name(): string;
    get voiceURI(): string;
}
export class SpeechSynthesisUtterance extends EventTarget {
    _lang: string | undefined;
    _pitch: number | undefined;
    _rate: number | undefined;
    _voice: SpeechSynthesisVoice | undefined;
    _volume: number | undefined;
    text: string;
    constructor(text: string);
    get lang(): string | undefined;
    set lang(value: string | undefined);
    get pitch(): number | undefined;
    set pitch(value: number);
    get rate(): number | undefined;
    set rate(value: number);
    get voice(): SpeechSynthesisVoice | undefined;
    set voice(value: SpeechSynthesisVoice | undefined);
    get volume(): number | undefined;
    set volume(value: number);
    onstart(): void;
    onend(): void;
    onerror(error: any): void;
    onsynthesisstart(): void;
    onsynthesiscompleted(): void;
    onboundary(_data: SpeechSynthesisEventProps): void;
    onviseme(_data: SpeechSynthesisEventProps): void;
    onmark(_data: SpeechSynthesisEventProps): void;
}
export default SpeechSynthesisUtterance;
export class SpeechSynthesis {
    speaking: boolean;
    speakerAudioDestination: SDK.SpeakerAudioDestination;
    audioConfig: SDK.AudioConfig | undefined;
    speechConfig: SDK.SpeechConfig | null;
    queue: Array<SpeechSynthesisUtterance>;
    canceled: boolean;
    synth: SDK.SpeechSynthesizer | null;
    synthesizing: boolean;
    constructor(options: PatchOptions);
    mute(): void;
    unmute(): void;
    getVolume(): number;
    setVolume(value: number): void;
    initSpeechSynthesizer(fetchCredentials: Function, speechSynthesisDeploymentId?: string): Promise<void>;
    createSynthesizer(voice: string | undefined, stream: SDK.AudioOutputStream | undefined | null): void;
    cancel(): void;
    pause(): void;
    resume(): void;
    getVoices: () => Array<SpeechSynthesisVoice>;
    onvoiceschanged: () => void;
    /**
     * Add events listeners to the events received by the synthesizer if callbakcs are given in the utterance
     * @param {SpeechSynthesisUtterance} utterance
     */
    linkEventsCallbacks(utterance: any): void;
    /**
     * Launch synthesis and play sound with the speech synthesizer
     * @param {SpeechSynthesisUtterance} utterance
     */
    speak(utterance: SpeechSynthesisUtterance, stream: SDK.AudioOutputStream | undefined | null): void;
    /**
     * Launch synthesis without sound being played and call callback function with an ArrayBuffer after synthesis finished, containing the sound data
     * @param {SpeechSynthesisUtterance} utterance
     * @param {Function} callback
     */
    synthesizeAndGetArrayData(utterance: any, callback: any): void;
    updateVoices(): Promise<void>;
}
export const createSpeechSynthesisPonyfill: (options: PatchOptions) => SpeechSynthesisPonyfillType;
export interface SpeechSynthesisPonyfillType {
    speechSynthesis: SpeechSynthesis;
    SpeechSynthesisUtterance: typeof SpeechSynthesisUtterance;
}
export interface SpeechRecognitionPonyfillType {
    speechRecognition: SpeechRecognition;
    SpeechGrammarList: typeof SpeechGrammarList;
}
export interface SpeechRecognitionProps {
    autoStart?: boolean;
    passive?: boolean;
    wakeWords?: Array<string>;
    continuous?: boolean;
    lang?: string;
    grammarsList?: Array<string> | string;
    interimResults?: boolean;
    timerBeforeSpeechEnd?: number;
    debug?: boolean;
}
declare class SpeechRecognition {
    audioConfig: SDK.AudioConfig | null;
    speechConfig: SDK.SpeechConfig | null;
    recognizer: SDK.SpeechRecognizer | null;
    enableTelemetry: boolean;
    looseEvents: boolean;
    referenceGrammars: any;
    textNormalization: string;
    started: boolean;
    constructor(options: PatchOptions, data?: SpeechRecognitionProps);
    get passive(): boolean;
    set passive(value: boolean);
    get wakeWords(): string[];
    set wakeWords(value: string[]);
    get continuous(): boolean;
    set continuous(value: boolean);
    get grammars(): SpeechGrammarList;
    set grammars(value: SpeechGrammarList);
    get interimResults(): boolean;
    set interimResults(value: boolean);
    get maxAlternatives(): number;
    set maxAlternatives(value: number);
    get lang(): string;
    set lang(value: string);
    onstart: () => void;
    onend: () => void;
    onpassivestart: () => void;
    onpassiveend: () => void;
    onaudiostart: () => void;
    onaudioend: () => void;
    onsoundstart: () => void;
    onsoundend: () => void;
    onspeechstart: () => void;
    onspeechend: () => void;
    onerror: (value: any) => void;
    onabort: () => void;
    onresult: (value: SpeechRecognitionResultList) => void;
    onpassiveresult: (value: Array<SpeechRecognitionResultListItem> | SpeechRecognitionResultList) => void;
    onwakeup: () => void;
    start: () => void;
    abort: Function | undefined;
    stop: Function | undefined;
    /**
     * Retrieval of credentials, initialization of speechConfig and start recognizing
     * @param fetchCredentials Function
     * @param speechRecognitionEndpointId string | undefined
     */
    initRecognizer: (fetchCredentials: Function, speechRecognitionEndpointId?: string, timerBeforeSpeechEnd?: number) => Promise<void>;
    /**
     * Create a new Synthesizer from audioConfig / speechConfig / lang
     * @param lang string
     */
    createRecognizer: () => Promise<void>;
    /**
     * Stop current recognizer, change language and start a new recognition
     * @param lang string
     */
    changeLanguage: (lang?: string) => Promise<void>;
    /**
     * In continuous mode, toggle from passive to active mode by stopping current recognition and starting a new one to prevent
     * receiving results from a current passive speech recognition.
     * If you don't care about having existing results in active recognition, just set recognition's 'passive' variable to 'false' instead
     * of using this method.
     */
    toggleContinuousPassiveToActive: () => Promise<void>;
    /**
     * In continuous mode, toggle from passive to active mode by stopping current recognition and starting a new one to prevent
     * receiving results from a current passive speech recognition.
     * If you don't care about having existing results in active recognition, just set recognition's 'passive' variable to 'false' instead
     * of using this method.
     */
    toggleContinuousActiveToPassive: () => Promise<void>;
    processSendEvent: (type: string, data?: any) => void;
    _startOnce(): Promise<void>;
}
export const createSpeechRecognitionPonyfill: (options: PatchOptions, data?: SpeechRecognitionProps) => {
    speechRecognition: SpeechRecognition;
    SpeechGrammarList: typeof SpeechGrammarList;
};
export function fetchAuthorizationToken({ region, subscriptionKey }: Credentials): Promise<string>;
export default function createSpeechServicesPonyfill(options: PatchOptions, recognitionData?: SpeechRecognitionProps): {
    speechSynthesis: SpeechSynthesis;
    SpeechSynthesisUtterance: typeof SpeechSynthesisUtterance;
    speechRecognition: import("data/SpeechToText/createSpeechRecognitionPonyfill").SpeechRecognition;
    SpeechGrammarList: typeof SpeechGrammarList;
};

//# sourceMappingURL=index.d.ts.map
