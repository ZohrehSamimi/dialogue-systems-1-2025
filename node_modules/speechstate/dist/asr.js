"use strict";
var __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {
    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }
    return new (P || (P = Promise))(function (resolve, reject) {
        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }
        function rejected(value) { try { step(generator["throw"](value)); } catch (e) { reject(e); } }
        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }
        step((generator = generator.apply(thisArg, _arguments || [])).next());
    });
};
Object.defineProperty(exports, "__esModule", { value: true });
exports.asrMachine = void 0;
const xstate_1 = require("xstate");
const web_speech_cognitive_services_davi_1 = require("@vladmaraev/web-speech-cognitive-services-davi");
exports.asrMachine = (0, xstate_1.setup)({
    types: {
        context: {},
        events: {},
        input: {},
    },
    delays: {
        noinputTimeout: ({ context }) => (context.params || {}).noInputTimeout || context.asrDefaultNoInputTimeout,
    },
    actions: {
        raise_noinput_after_timeout: (0, xstate_1.raise)({ type: "NOINPUT" }, {
            delay: "noinputTimeout",
            id: "timeout",
        }),
        cancel_noinput_timeout: (0, xstate_1.cancel)("timeout"),
    },
    guards: {
        nlu_is_activated: ({ context }) => {
            const nlu = (context.params || {}).nlu;
            if (nlu) {
                if (typeof nlu === "object") {
                    return true;
                }
                else if (context.azureLanguageCredentials) {
                    return true;
                }
            }
            return false;
        },
    },
    actors: {
        new_ponyfill: (0, xstate_1.fromCallback)(({ sendBack, input, receive }) => {
            const { speechRecognition } = (0, web_speech_cognitive_services_davi_1.default)({
                audioContext: input.audioContext,
                speechRecognitionEndpointId: input.speechRecognitionEndpointId,
                credentials: {
                    region: input.azureRegion,
                    authorizationToken: input.azureAuthorizationToken,
                },
            }, {
                passive: false,
                interimResults: true,
                continuous: true,
                lang: input.locale || "en-US",
                grammarsList: input.hints,
                autoStart: true,
                timerBeforeSpeechEnd: input.completeTimeout,
                // debug: true,
            });
            let asr = speechRecognition;
            asr.onresult = function (event) {
                if (event.isFinal) {
                    const transcript = event
                        .map((x) => x.transcript.replace(/\.$/, ""))
                        .join(" ");
                    const confidence = event
                        .map((x) => x.confidence)
                        .reduce((a, b) => a + b) / event.length;
                    const res = [
                        {
                            utterance: transcript,
                            confidence: confidence,
                        },
                    ];
                    sendBack({
                        type: "RECOGNISED",
                        value: res,
                    });
                }
                else {
                    sendBack({ type: "STARTSPEECH" });
                }
            };
            asr.onstart = function () {
                sendBack({ type: "STARTED" });
            };
            asr.onend = function () {
                sendBack({ type: "LISTEN_COMPLETE" });
            };
            // any: it works, but gives unexpected type error
            asr.onabort = function () {
                sendBack({ type: "LISTEN_COMPLETE" });
            };
            console.debug("[ASR] READY", asr);
            sendBack({ type: "READY", value: asr });
            receive((event) => {
                if (event.type === "STOP") {
                    console.log("[asr.callback] Receiving STOP");
                    asr.abort();
                }
            });
        }),
        nluPromise: (0, xstate_1.fromPromise)((_a) => __awaiter(void 0, [_a], void 0, function* ({ input }) {
            const response = yield fetch(new Request(input.endpoint, {
                method: "POST",
                headers: {
                    "Ocp-Apim-Subscription-Key": input.key,
                    "Content-Type": "application/json",
                },
                body: JSON.stringify({
                    kind: "Conversation",
                    analysisInput: {
                        conversationItem: {
                            id: "PARTICIPANT_ID_HERE",
                            text: input.query,
                            modality: "text",
                            language: input.locale,
                            participantId: "PARTICIPANT_ID_HERE",
                        },
                    },
                    parameters: {
                        projectName: input.projectName,
                        verbose: true,
                        deploymentName: input.deploymentName,
                        stringIndexType: "TextElement_V8",
                    },
                }),
            }));
            return response.json();
        })),
    },
}).createMachine({
    id: "asr",
    context: ({ input }) => ({
        azureAuthorizationToken: input.azureAuthorizationToken,
        asrDefaultCompleteTimeout: input.asrDefaultCompleteTimeout || 0,
        asrDefaultNoInputTimeout: input.asrDefaultNoInputTimeout || 5000,
        locale: input.locale || "en-US",
        audioContext: input.audioContext,
        azureRegion: input.azureRegion,
        azureLanguageCredentials: input.azureLanguageCredentials,
        speechRecognitionEndpointId: input.speechRecognitionEndpointId,
    }),
    initial: "Ready",
    on: {
        NEW_TOKEN: {
            actions: (0, xstate_1.assign)(({ event }) => {
                return { azureAuthorizationToken: event.value };
            }),
        },
    },
    states: {
        Fail: {},
        Ready: {
            entry: (0, xstate_1.sendParent)({ type: "ASR_READY" }),
            on: {
                START: {
                    target: "Recognising",
                    actions: (0, xstate_1.assign)(({ event }) => ({
                        params: event.value,
                    })),
                },
            },
        },
        Recognising: {
            onDone: "Ready",
            invoke: {
                id: "asr",
                src: "new_ponyfill",
                input: ({ context }) => ({
                    azureRegion: context.azureRegion,
                    audioContext: context.audioContext,
                    azureAuthorizationToken: context.azureAuthorizationToken,
                    locale: (context.params || {}).locale || context.locale,
                    speechRecognitionEndpointId: context.speechRecognitionEndpointId,
                    completeTimeout: (context.params || {}).completeTimeout ||
                        context.asrDefaultCompleteTimeout,
                    hints: (context.params || {}).hints,
                }),
            },
            on: {
                STOP: {
                    target: ".WaitToStop",
                },
                CONTROL: {
                    target: ".Pausing",
                },
                NOINPUT: {
                    actions: (0, xstate_1.sendParent)({ type: "ASR_NOINPUT" }),
                    target: ".WaitToStop",
                },
            },
            initial: "WaitForRecogniser",
            states: {
                WaitForRecogniser: {
                    on: {
                        STARTED: {
                            target: "NoInput",
                            actions: [
                                () => console.debug("[ASR] STARTED"),
                                (0, xstate_1.sendParent)({ type: "ASR_STARTED" }),
                            ],
                        },
                    },
                },
                NoInput: {
                    entry: { type: "raise_noinput_after_timeout" },
                    on: {
                        STARTSPEECH: {
                            target: "InProgress",
                            actions: (0, xstate_1.cancel)("completeTimeout"),
                        },
                    },
                    exit: { type: "cancel_noinput_timeout" },
                },
                InProgress: {
                    entry: () => console.debug("[ASR] in progress"),
                    on: {
                        RECOGNISED: [
                            {
                                target: "NLURequest",
                                guard: { type: "nlu_is_activated" },
                                actions: (0, xstate_1.assign)({
                                    result: ({ event }) => event.value,
                                }),
                            },
                            {
                                target: "WaitToStop",
                                actions: [
                                    (0, xstate_1.assign)({
                                        result: ({ event }) => event.value,
                                    }),
                                    (0, xstate_1.sendParent)(({ context }) => ({
                                        type: "RECOGNISED",
                                        value: context.result,
                                    })),
                                ],
                            },
                        ],
                    },
                },
                WaitToStop: {
                    entry: (0, xstate_1.sendTo)("asr", { type: "STOP" }),
                    on: {
                        LISTEN_COMPLETE: {
                            actions: (0, xstate_1.sendParent)({ type: "LISTEN_COMPLETE" }),
                            target: "Stopped",
                        },
                    },
                },
                Pausing: {
                    onDone: "#asr.Recognising",
                    initial: "WaitToPause",
                    states: {
                        WaitToPause: {
                            entry: (0, xstate_1.sendTo)("asr", { type: "STOP" }),
                            on: {
                                LISTEN_COMPLETE: {
                                    target: "Paused",
                                },
                            },
                        },
                        Paused: {
                            entry: (0, xstate_1.sendParent)({ type: "ASR_PAUSED" }),
                            on: {
                                CONTROL: {
                                    target: "Continue",
                                    //       ///// todo? reset noInputTimeout
                                },
                            },
                        },
                        Continue: { type: "final" },
                    },
                },
                NLURequest: {
                    invoke: {
                        src: "nluPromise",
                        input: ({ context }) => {
                            let c;
                            typeof context.params.nlu === "boolean"
                                ? (c = context.azureLanguageCredentials)
                                : (c = context.params.nlu);
                            return {
                                endpoint: c.endpoint,
                                key: c.key,
                                projectName: c.projectName,
                                deploymentName: c.deploymentName,
                                query: context.result[0].utterance,
                                locale: (context.params || {}).locale || context.locale,
                            };
                        },
                        onDone: [
                            {
                                actions: [
                                    ({ event }) => console.error("[ASR] no NLU prediction", event.output),
                                    (0, xstate_1.sendParent)(({ context }) => ({
                                        type: "RECOGNISED",
                                        value: context.result,
                                    })),
                                ],
                                target: "WaitToStop",
                                guard: ({ event }) => !(event.output.result || {}).prediction,
                            },
                            {
                                actions: [
                                    ({ event }) => console.debug("[ASR] NLU result", event.output.result.prediction),
                                    (0, xstate_1.sendParent)(({ context, event }) => ({
                                        type: "RECOGNISED",
                                        value: context.result,
                                        nluValue: event.output.result.prediction,
                                    })),
                                ],
                                target: "WaitToStop",
                            },
                        ],
                        onError: {
                            actions: [
                                ({ event }) => console.error("[ASR]", event.error),
                                (0, xstate_1.sendParent)(({ context }) => ({
                                    type: "RECOGNISED",
                                    value: context.result,
                                })),
                            ],
                            target: "WaitToStop",
                        },
                    },
                },
                Stopped: { type: "final" },
            },
        },
    },
});
